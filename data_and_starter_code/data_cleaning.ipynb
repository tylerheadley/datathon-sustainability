{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499baba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path('.') / 'data'\n",
    "train = pd.read_csv(data_path / \"train.csv\")\n",
    "client = pd.read_csv(data_path / \"client.csv\")\n",
    "historical_weather = pd.read_csv(data_path / \"historical_weather.csv\")\n",
    "forecast_weather = pd.read_csv(data_path / \"forecast_weather.csv\")\n",
    "electricity = pd.read_csv(data_path / \"electricity_prices.csv\")\n",
    "gas = pd.read_csv(data_path / \"gas_prices.csv\")\n",
    "\n",
    "location = (pd.read_csv(data_path / \"county_lon_lats.csv\")\n",
    "            .drop(columns=[\"Unnamed: 0\"])\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e03fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureProcessorClass():\n",
    "    def __init__(self):         \n",
    "        # Columns to join on for the different datasets\n",
    "        self.weather_join = ['datetime', 'county', 'data_block_id']\n",
    "        self.gas_join = ['data_block_id']\n",
    "        self.electricity_join = ['datetime', 'data_block_id']\n",
    "        self.client_join = ['county', 'is_business', 'product_type', 'data_block_id']\n",
    "        \n",
    "        # Columns of latitude & longitude\n",
    "        self.lat_lon_columns = ['latitude', 'longitude']\n",
    "        \n",
    "        # Aggregate stats \n",
    "        self.agg_stats = ['mean'] #, 'min', 'max', 'std', 'median']\n",
    "        \n",
    "        # Categorical columns (specify for XGBoost)\n",
    "        self.category_columns = ['county', 'is_business', 'product_type', 'is_consumption', 'data_block_id']\n",
    "\n",
    "    def create_new_column_names(self, df, suffix, columns_no_change):\n",
    "        '''Change column names by given suffix, keep columns_no_change, and return back the data'''\n",
    "        df.columns = [col + suffix \n",
    "                      if col not in columns_no_change\n",
    "                      else col\n",
    "                      for col in df.columns\n",
    "                      ]\n",
    "        return df \n",
    "\n",
    "    def flatten_multi_index_columns(self, df):\n",
    "        df.columns = ['_'.join([col for col in multi_col if len(col)>0]) \n",
    "                      for multi_col in df.columns]\n",
    "        return df\n",
    "    \n",
    "    def create_data_features(self, data):\n",
    "        '''üìäCreate features for main data (test or train) setüìä'''\n",
    "        # To datetime\n",
    "        data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "        \n",
    "        # Time period features\n",
    "        data['date'] = data['datetime'].dt.normalize()\n",
    "        data['year'] = data['datetime'].dt.year\n",
    "        data['quarter'] = data['datetime'].dt.quarter\n",
    "        data['month'] = data['datetime'].dt.month\n",
    "        data['week'] = data['datetime'].dt.isocalendar().week\n",
    "        data['hour'] = data['datetime'].dt.hour\n",
    "        \n",
    "        # Day features\n",
    "        data['day_of_year'] = data['datetime'].dt.day_of_year\n",
    "        data['day_of_month']  = data['datetime'].dt.day\n",
    "        data['day_of_week'] = data['datetime'].dt.day_of_week\n",
    "        return data\n",
    "\n",
    "    def create_client_features(self, client):\n",
    "        '''üíº Create client features üíº'''\n",
    "        # Modify column names - specify suffix\n",
    "        client = self.create_new_column_names(client, \n",
    "                                           suffix='_client',\n",
    "                                           columns_no_change = self.client_join\n",
    "                                          )       \n",
    "        return client\n",
    "    \n",
    "    def create_historical_weather_features(self, historical_weather):\n",
    "        '''‚åõüå§Ô∏è Create historical weather features üå§Ô∏è‚åõ'''\n",
    "        \n",
    "        # To datetime\n",
    "        historical_weather['datetime'] = pd.to_datetime(historical_weather['datetime'])\n",
    "        \n",
    "        # Add county\n",
    "        historical_weather[self.lat_lon_columns] = historical_weather[self.lat_lon_columns].astype(float).round(1)\n",
    "        historical_weather = historical_weather.merge(location, how = 'left', on = self.lat_lon_columns)\n",
    "\n",
    "        # Modify column names - specify suffix\n",
    "        historical_weather = self.create_new_column_names(historical_weather,\n",
    "                                                          suffix='_h',\n",
    "                                                          columns_no_change = self.lat_lon_columns + self.weather_join\n",
    "                                                          ) \n",
    "        \n",
    "        # Group by & calculate aggregate stats \n",
    "        agg_columns = [col for col in historical_weather.columns if col not in self.lat_lon_columns + self.weather_join]\n",
    "        agg_dict = {agg_col: self.agg_stats for agg_col in agg_columns}\n",
    "        historical_weather = historical_weather.groupby(self.weather_join).agg(agg_dict).reset_index() \n",
    "        \n",
    "        # Flatten the multi column aggregates\n",
    "        historical_weather = self.flatten_multi_index_columns(historical_weather) \n",
    "        \n",
    "        # Test set has 1 day offset for hour<11 and 2 day offset for hour>11\n",
    "        historical_weather['hour_h'] = historical_weather['datetime'].dt.hour\n",
    "        historical_weather['datetime'] = (historical_weather\n",
    "                                               .apply(lambda x: \n",
    "                                                      x['datetime'] + pd.DateOffset(1) \n",
    "                                                      if x['hour_h']< 11 \n",
    "                                                      else x['datetime'] + pd.DateOffset(2),\n",
    "                                                      axis=1)\n",
    "                                              )\n",
    "        \n",
    "        return historical_weather\n",
    "    \n",
    "    def create_forecast_weather_features(self, forecast_weather):\n",
    "        '''üîÆüå§Ô∏è Create forecast weather features üå§Ô∏èüîÆ'''\n",
    "        \n",
    "        # Rename column and drop\n",
    "        forecast_weather = (forecast_weather\n",
    "                            .rename(columns = {'forecast_datetime': 'datetime'})\n",
    "                            .drop(columns = 'origin_datetime') # not needed\n",
    "                           )\n",
    "        \n",
    "        # To datetime\n",
    "        forecast_weather['datetime'] = (pd.to_datetime(forecast_weather['datetime'])\n",
    "                                        .dt\n",
    "                                        .tz_localize(None)\n",
    "                                       )\n",
    "\n",
    "        # Add county\n",
    "        forecast_weather[self.lat_lon_columns] = forecast_weather[self.lat_lon_columns].astype(float).round(1)\n",
    "        forecast_weather = forecast_weather.merge(location, how = 'left', on = self.lat_lon_columns)\n",
    "        \n",
    "        # Modify column names - specify suffix\n",
    "        forecast_weather = self.create_new_column_names(forecast_weather,\n",
    "                                                        suffix='_f',\n",
    "                                                        columns_no_change = self.lat_lon_columns + self.weather_join\n",
    "                                                        ) \n",
    "        \n",
    "        # Group by & calculate aggregate stats \n",
    "        agg_columns = [col for col in forecast_weather.columns if col not in self.lat_lon_columns + self.weather_join]\n",
    "        agg_dict = {agg_col: self.agg_stats for agg_col in agg_columns}\n",
    "        forecast_weather = forecast_weather.groupby(self.weather_join).agg(agg_dict).reset_index() \n",
    "        \n",
    "        # Flatten the multi column aggregates\n",
    "        forecast_weather = self.flatten_multi_index_columns(forecast_weather)     \n",
    "        return forecast_weather\n",
    "\n",
    "    def create_electricity_features(self, electricity):\n",
    "        '''‚ö° Create electricity prices features ‚ö°'''\n",
    "        # To datetime\n",
    "        electricity['forecast_date'] = pd.to_datetime(electricity['forecast_date'])\n",
    "        \n",
    "        # Test set has 1 day offset\n",
    "        electricity['datetime'] = electricity['forecast_date'] + pd.DateOffset(1)\n",
    "        \n",
    "        # Modify column names - specify suffix\n",
    "        electricity = self.create_new_column_names(electricity, \n",
    "                                                   suffix='_electricity',\n",
    "                                                   columns_no_change = self.electricity_join\n",
    "                                                  )             \n",
    "        return electricity\n",
    "\n",
    "    def create_gas_features(self, gas):\n",
    "        '''‚õΩ Create gas prices features ‚õΩ'''\n",
    "        # Mean gas price\n",
    "        gas['mean_price_per_mwh'] = (gas['lowest_price_per_mwh'] + gas['highest_price_per_mwh'])/2\n",
    "        \n",
    "        # Modify column names - specify suffix\n",
    "        gas = self.create_new_column_names(gas, \n",
    "                                           suffix='_gas',\n",
    "                                           columns_no_change = self.gas_join\n",
    "                                          )       \n",
    "        return gas\n",
    "    \n",
    "    def __call__(self, data, client, historical_weather, forecast_weather, electricity, gas):\n",
    "        '''Processing of features from all datasets, merge together and return features for dataframe df '''\n",
    "        # Create features for relevant dataset\n",
    "        data = self.create_data_features(data)\n",
    "        client = self.create_client_features(client)\n",
    "        historical_weather = self.create_historical_weather_features(historical_weather)\n",
    "        forecast_weather = self.create_forecast_weather_features(forecast_weather)\n",
    "        electricity = self.create_electricity_features(electricity)\n",
    "        gas = self.create_gas_features(gas)\n",
    "        \n",
    "        # üîó Merge all datasets into one df üîó\n",
    "        df = data.merge(client, how='left', on = self.client_join)\n",
    "        df = df.merge(historical_weather, how='left', on = self.weather_join)\n",
    "        df = df.merge(forecast_weather, how='left', on = self.weather_join)\n",
    "        df = df.merge(electricity, how='left', on = self.electricity_join)\n",
    "        df = df.merge(gas, how='left', on = self.gas_join)\n",
    "        \n",
    "        # Change columns to categorical for XGBoost\n",
    "        df[self.category_columns] = df[self.category_columns].astype('category')\n",
    "        return df\n",
    "    \n",
    "def create_revealed_targets_train(data, N_day_lags):\n",
    "    '''üéØ Create past revealed_targets for train set based on number of day lags N_day_lags üéØ '''    \n",
    "    original_datetime = data['datetime']\n",
    "    revealed_targets = data[['datetime', 'prediction_unit_id', 'is_consumption', 'target']].copy()\n",
    "    \n",
    "    # Create revealed targets for all day lags\n",
    "    for day_lag in range(2, N_day_lags+1):\n",
    "        revealed_targets['datetime'] = original_datetime + pd.DateOffset(day_lag)\n",
    "        data = data.merge(revealed_targets, \n",
    "                          how='left', \n",
    "                          on = ['datetime', 'prediction_unit_id', 'is_consumption'],\n",
    "                          suffixes = ('', f'_{day_lag}_days_ago')\n",
    "                         )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a4eb7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features for training data\n",
    "# NOTE: this can take a little bit to run\n",
    "FeatureProcessor = FeatureProcessorClass()\n",
    "N_day_lags = 15  # incorporate data from historical 15 days\n",
    "\n",
    "\n",
    "data = FeatureProcessor(data = train.copy(),\n",
    "                      client = client.copy(),\n",
    "                      historical_weather = historical_weather.copy(),\n",
    "                      forecast_weather = forecast_weather.copy(),\n",
    "                      electricity = electricity.copy(),\n",
    "                      gas = gas.copy(),\n",
    "                     )\n",
    "\n",
    "df = create_revealed_targets_train(data.copy(), \n",
    "                                  N_day_lags = N_day_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57386bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features to CSV\n",
    "df.to_csv('train_features.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa6fb563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['county', 'is_business', 'product_type', 'target', 'is_consumption',\n",
       "       'datetime', 'data_block_id', 'row_id', 'prediction_unit_id', 'date',\n",
       "       'year', 'quarter', 'month', 'week', 'hour', 'day_of_year',\n",
       "       'day_of_month', 'day_of_week', 'eic_count_client',\n",
       "       'installed_capacity_client', 'date_client', 'temperature_h_mean',\n",
       "       'dewpoint_h_mean', 'rain_h_mean', 'snowfall_h_mean',\n",
       "       'surface_pressure_h_mean', 'cloudcover_total_h_mean',\n",
       "       'cloudcover_low_h_mean', 'cloudcover_mid_h_mean',\n",
       "       'cloudcover_high_h_mean', 'windspeed_10m_h_mean',\n",
       "       'winddirection_10m_h_mean', 'shortwave_radiation_h_mean',\n",
       "       'direct_solar_radiation_h_mean', 'diffuse_radiation_h_mean', 'hour_h',\n",
       "       'hours_ahead_f_mean', 'temperature_f_mean', 'dewpoint_f_mean',\n",
       "       'cloudcover_high_f_mean', 'cloudcover_low_f_mean',\n",
       "       'cloudcover_mid_f_mean', 'cloudcover_total_f_mean',\n",
       "       '10_metre_u_wind_component_f_mean', '10_metre_v_wind_component_f_mean',\n",
       "       'direct_solar_radiation_f_mean',\n",
       "       'surface_solar_radiation_downwards_f_mean', 'snowfall_f_mean',\n",
       "       'total_precipitation_f_mean', 'forecast_date_electricity',\n",
       "       'euros_per_mwh_electricity', 'origin_date_electricity',\n",
       "       'forecast_date_gas', 'lowest_price_per_mwh_gas',\n",
       "       'highest_price_per_mwh_gas', 'origin_date_gas',\n",
       "       'mean_price_per_mwh_gas', 'target_2_days_ago', 'target_3_days_ago',\n",
       "       'target_4_days_ago', 'target_5_days_ago', 'target_6_days_ago',\n",
       "       'target_7_days_ago', 'target_8_days_ago', 'target_9_days_ago',\n",
       "       'target_10_days_ago', 'target_11_days_ago', 'target_12_days_ago',\n",
       "       'target_13_days_ago', 'target_14_days_ago', 'target_15_days_ago'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e930eb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>target</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>datetime</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>prediction_unit_id</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>target_6_days_ago</th>\n",
       "      <th>target_7_days_ago</th>\n",
       "      <th>target_8_days_ago</th>\n",
       "      <th>target_9_days_ago</th>\n",
       "      <th>target_10_days_ago</th>\n",
       "      <th>target_11_days_ago</th>\n",
       "      <th>target_12_days_ago</th>\n",
       "      <th>target_13_days_ago</th>\n",
       "      <th>target_14_days_ago</th>\n",
       "      <th>target_15_days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96.590</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17.314</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.904</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>656.859</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>501.760</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  county is_business product_type   target is_consumption   datetime  \\\n",
       "0      0           0            1    0.713              0 2021-09-01   \n",
       "1      0           0            1   96.590              1 2021-09-01   \n",
       "2      0           0            2    0.000              0 2021-09-01   \n",
       "3      0           0            2   17.314              1 2021-09-01   \n",
       "4      0           0            3    2.904              0 2021-09-01   \n",
       "5      0           0            3  656.859              1 2021-09-01   \n",
       "6      0           1            0    0.000              0 2021-09-01   \n",
       "7      0           1            0   59.000              1 2021-09-01   \n",
       "8      0           1            1    0.000              0 2021-09-01   \n",
       "9      0           1            1  501.760              1 2021-09-01   \n",
       "\n",
       "  data_block_id  row_id  prediction_unit_id       date  ...  \\\n",
       "0             0       0                   0 2021-09-01  ...   \n",
       "1             0       1                   0 2021-09-01  ...   \n",
       "2             0       2                   1 2021-09-01  ...   \n",
       "3             0       3                   1 2021-09-01  ...   \n",
       "4             0       4                   2 2021-09-01  ...   \n",
       "5             0       5                   2 2021-09-01  ...   \n",
       "6             0       6                   3 2021-09-01  ...   \n",
       "7             0       7                   3 2021-09-01  ...   \n",
       "8             0       8                   4 2021-09-01  ...   \n",
       "9             0       9                   4 2021-09-01  ...   \n",
       "\n",
       "   target_6_days_ago  target_7_days_ago  target_8_days_ago  target_9_days_ago  \\\n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN                NaN   \n",
       "2                NaN                NaN                NaN                NaN   \n",
       "3                NaN                NaN                NaN                NaN   \n",
       "4                NaN                NaN                NaN                NaN   \n",
       "5                NaN                NaN                NaN                NaN   \n",
       "6                NaN                NaN                NaN                NaN   \n",
       "7                NaN                NaN                NaN                NaN   \n",
       "8                NaN                NaN                NaN                NaN   \n",
       "9                NaN                NaN                NaN                NaN   \n",
       "\n",
       "   target_10_days_ago  target_11_days_ago  target_12_days_ago  \\\n",
       "0                 NaN                 NaN                 NaN   \n",
       "1                 NaN                 NaN                 NaN   \n",
       "2                 NaN                 NaN                 NaN   \n",
       "3                 NaN                 NaN                 NaN   \n",
       "4                 NaN                 NaN                 NaN   \n",
       "5                 NaN                 NaN                 NaN   \n",
       "6                 NaN                 NaN                 NaN   \n",
       "7                 NaN                 NaN                 NaN   \n",
       "8                 NaN                 NaN                 NaN   \n",
       "9                 NaN                 NaN                 NaN   \n",
       "\n",
       "   target_13_days_ago  target_14_days_ago  target_15_days_ago  \n",
       "0                 NaN                 NaN                 NaN  \n",
       "1                 NaN                 NaN                 NaN  \n",
       "2                 NaN                 NaN                 NaN  \n",
       "3                 NaN                 NaN                 NaN  \n",
       "4                 NaN                 NaN                 NaN  \n",
       "5                 NaN                 NaN                 NaN  \n",
       "6                 NaN                 NaN                 NaN  \n",
       "7                 NaN                 NaN                 NaN  \n",
       "8                 NaN                 NaN                 NaN  \n",
       "9                 NaN                 NaN                 NaN  \n",
       "\n",
       "[10 rows x 71 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
